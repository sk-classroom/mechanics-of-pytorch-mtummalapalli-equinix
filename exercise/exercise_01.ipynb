{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a first neural network using PyTorch \n",
    "\n",
    "In this exercise, we will learn how to implement a neural network using PyTorch. \n",
    "\n",
    "## Single Layer Neural Network \n",
    "\n",
    "Let's implmement a single layer neural network, namely \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x &= [x_1, \\ldots, x_m] \\\\\n",
    "g(x) &= \\sum_{j=1}^n w_j x_{ij} + b\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "We will use the King County housing dataset [link](https://www.kaggle.com/datasets/harlfoxem/housesalesprediction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_yr</th>\n",
       "      <th>sale_month</th>\n",
       "      <th>sale_day</th>\n",
       "      <th>view</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>...</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>221900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>538000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>604000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>510000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "      <td>360000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "      <td>402101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "      <td>325000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sale_yr  sale_month  sale_day  view  waterfront      lat     long  \\\n",
       "0         2014          10        13     0           0  47.5112 -122.257   \n",
       "1         2014          12         9     0           0  47.7210 -122.319   \n",
       "2         2015           2        25     0           0  47.7379 -122.233   \n",
       "3         2014          12         9     0           0  47.5208 -122.393   \n",
       "4         2015           2        18     0           0  47.6168 -122.045   \n",
       "...        ...         ...       ...   ...         ...      ...      ...   \n",
       "21608     2014           5        21     0           0  47.6993 -122.346   \n",
       "21609     2015           2        23     0           0  47.5107 -122.362   \n",
       "21610     2014           6        23     0           0  47.5944 -122.299   \n",
       "21611     2015           1        16     0           0  47.5345 -122.069   \n",
       "21612     2014          10        15     0           0  47.5941 -122.299   \n",
       "\n",
       "       bedrooms  bathrooms  sqft_living  ...  condition  grade  sqft_above  \\\n",
       "0             3       1.00         1180  ...          3      7        1180   \n",
       "1             3       2.25         2570  ...          3      7        2170   \n",
       "2             2       1.00          770  ...          3      6         770   \n",
       "3             4       3.00         1960  ...          5      7        1050   \n",
       "4             3       2.00         1680  ...          3      8        1680   \n",
       "...         ...        ...          ...  ...        ...    ...         ...   \n",
       "21608         3       2.50         1530  ...          3      8        1530   \n",
       "21609         4       2.50         2310  ...          3      8        2310   \n",
       "21610         2       0.75         1020  ...          3      7        1020   \n",
       "21611         3       2.50         1600  ...          3      8        1600   \n",
       "21612         2       0.75         1020  ...          3      7        1020   \n",
       "\n",
       "       sqft_basement  yr_built  yr_renovated  zipcode  sqft_living15  \\\n",
       "0                  0      1955             0    98178           1340   \n",
       "1                400      1951          1991    98125           1690   \n",
       "2                  0      1933             0    98028           2720   \n",
       "3                910      1965             0    98136           1360   \n",
       "4                  0      1987             0    98074           1800   \n",
       "...              ...       ...           ...      ...            ...   \n",
       "21608              0      2009             0    98103           1530   \n",
       "21609              0      2014             0    98146           1830   \n",
       "21610              0      2009             0    98144           1020   \n",
       "21611              0      2004             0    98027           1410   \n",
       "21612              0      2008             0    98144           1020   \n",
       "\n",
       "       sqft_lot15     price  \n",
       "0            5650  221900.0  \n",
       "1            7639  538000.0  \n",
       "2            8062  180000.0  \n",
       "3            5000  604000.0  \n",
       "4            7503  510000.0  \n",
       "...           ...       ...  \n",
       "21608        1509  360000.0  \n",
       "21609        7200  400000.0  \n",
       "21610        2007  402101.0  \n",
       "21611        1287  400000.0  \n",
       "21612        1357  325000.0  \n",
       "\n",
       "[21613 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.datasets import fetch_california_housing\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_table = pd.read_csv(\"../../data/kc_house_data.csv\")\n",
    "data_table[\"sale_yr\"] = pd.to_numeric(data_table.date.str.slice(0, 4))\n",
    "data_table[\"sale_month\"] = pd.to_numeric(data_table.date.str.slice(4, 6))\n",
    "data_table[\"sale_day\"] = pd.to_numeric(data_table.date.str.slice(6, 8))\n",
    "data_table = pd.DataFrame(\n",
    "    data_table,\n",
    "    columns=[\n",
    "        \"sale_yr\",\n",
    "        \"sale_month\",\n",
    "        \"sale_day\",\n",
    "        \"view\",\n",
    "        \"waterfront\",\n",
    "        \"lat\",\n",
    "        \"long\",\n",
    "        \"bedrooms\",\n",
    "        \"bathrooms\",\n",
    "        \"sqft_living\",\n",
    "        \"sqft_lot\",\n",
    "        \"floors\",\n",
    "        \"condition\",\n",
    "        \"grade\",\n",
    "        \"sqft_above\",\n",
    "        \"sqft_basement\",\n",
    "        \"yr_built\",\n",
    "        \"yr_renovated\",\n",
    "        \"zipcode\",\n",
    "        \"sqft_living15\",\n",
    "        \"sqft_lot15\",\n",
    "        \"price\",\n",
    "    ],\n",
    ")\n",
    "data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_table[\"price\"].values / 1000\n",
    "X = data_table.drop(\"price\", axis=1).values\n",
    "# housing = fetch_california_housing()\n",
    "# X, y = housing.data, housing.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test set. Use 80% of the data for training and 20% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the features using its mean and standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to the data to PyTorch Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert to PyTorch tensors\n",
    "import torch\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Prepare the dataset for batching\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & Training \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the model\n",
    "\n",
    "\n",
    "class SingleLayerNN(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SingleLayerNN, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = SingleLayerNN(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the loss function and optimizer\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/mambaforge/base/envs/netdatasci/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/usr/local/Caskroom/mambaforge/base/envs/netdatasci/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 431348.085101476\n",
      "Epoch 10, Average Loss: 430715.12984317343\n",
      "Epoch 15, Average Loss: 428908.4181849631\n",
      "Epoch 20, Average Loss: 427102.56636300735\n",
      "Epoch 25, Average Loss: 426367.06025138375\n",
      "Epoch 30, Average Loss: 425470.2105627306\n",
      "Epoch 35, Average Loss: 423271.5787592251\n",
      "Epoch 40, Average Loss: 421271.07645295205\n",
      "Epoch 45, Average Loss: 420328.06036669743\n",
      "Epoch 50, Average Loss: 418667.73166512913\n",
      "Epoch 55, Average Loss: 417383.1949377306\n",
      "Epoch 60, Average Loss: 415629.65457795205\n",
      "Epoch 65, Average Loss: 414352.7849400369\n",
      "Epoch 70, Average Loss: 412573.8754035978\n",
      "Epoch 75, Average Loss: 411592.56757380074\n",
      "Epoch 80, Average Loss: 410019.2931273063\n",
      "Epoch 85, Average Loss: 408560.7741005535\n",
      "Epoch 90, Average Loss: 407463.5655558118\n",
      "Epoch 95, Average Loss: 406001.59968865314\n",
      "Epoch 100, Average Loss: 404784.6054543358\n"
     ]
    }
   ],
   "source": [
    "# Training loop with DataLoader\n",
    "n_epochs = 100\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= len(train_loader)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 370709.18290441175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/mambaforge/base/envs/netdatasci/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        predictions = model(inputs)\n",
    "        test_loss = criterion(predictions, labels)\n",
    "        total_loss += test_loss.item()\n",
    "average_loss = total_loss / len(test_loader)\n",
    "print(f\"Test Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper neural networks\n",
    "\n",
    "Define a deeper model w/ non-linear activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17290, 21), (17290,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define a deeper model w/ non-linear activation function and add dropout to prevent overfitting\n",
    "\n",
    "\n",
    "class MultiLayerNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, dropout_rate=0.5):\n",
    "        super(MultiLayerNN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = torch.nn.Linear(hidden_size, 1)\n",
    "        self.relu = torch.nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = MultiLayerNN(X_train.shape[1])\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/mambaforge/base/envs/netdatasci/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/usr/local/Caskroom/mambaforge/base/envs/netdatasci/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 141209.373255881\n",
      "Epoch 10, Average Loss: 139742.59127075647\n",
      "Epoch 15, Average Loss: 139012.73214079798\n",
      "Epoch 20, Average Loss: 138837.38726648985\n",
      "Epoch 25, Average Loss: 138670.0625144142\n",
      "Epoch 30, Average Loss: 138623.6017642989\n",
      "Epoch 35, Average Loss: 138595.52937615314\n",
      "Epoch 40, Average Loss: 138593.56381169282\n",
      "Epoch 45, Average Loss: 138523.37257841328\n",
      "Epoch 50, Average Loss: 139482.01759974632\n",
      "Epoch 55, Average Loss: 138987.8526435655\n",
      "Epoch 60, Average Loss: 138489.50442516143\n",
      "Epoch 65, Average Loss: 138467.61645237546\n",
      "Epoch 70, Average Loss: 138468.69299901984\n",
      "Epoch 75, Average Loss: 138424.08750864852\n",
      "Epoch 80, Average Loss: 138461.15707881688\n",
      "Epoch 85, Average Loss: 138855.76011877306\n",
      "Epoch 90, Average Loss: 138645.0666368773\n",
      "Epoch 95, Average Loss: 139324.06627652215\n",
      "Epoch 100, Average Loss: 138448.26095479704\n",
      "Test Loss: 118547.0838694853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/mambaforge/base/envs/netdatasci/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Run the training loop and evaluate the model\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 100\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= len(train_loader)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {epoch_loss}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        predictions = model(inputs)\n",
    "        test_loss = criterion(predictions, labels)\n",
    "        total_loss += test_loss.item()\n",
    "average_loss = total_loss / len(test_loader)\n",
    "print(f\"Test Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define a deeper model w/ non-linear activation function\n",
    "\n",
    "\n",
    "class MultiLayerNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=32):\n",
    "        super(MultiLayerNN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = torch.nn.Linear(hidden_size, 1)\n",
    "        self.dropout = torch.nn.Dropout(p=0.1)\n",
    "        self.relu = torch.nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = MultiLayerNN(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 143405.00063422509\n",
      "Epoch 20, Average Loss: 142172.27642124076\n",
      "Epoch 30, Average Loss: 142194.90584640222\n",
      "Epoch 40, Average Loss: 141833.34426891143\n",
      "Epoch 50, Average Loss: 141228.6308521679\n",
      "Test Loss: 118687.990234375\n"
     ]
    }
   ],
   "source": [
    "# TODO: Run the training loop and evaluate the model\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 50\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= len(train_loader)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {epoch_loss}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        predictions = model(inputs)\n",
    "        test_loss = criterion(predictions, labels)\n",
    "        total_loss += test_loss.item()\n",
    "average_loss = total_loss / len(test_loader)\n",
    "print(f\"Test Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applsoftcomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
